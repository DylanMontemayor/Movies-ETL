# Movies-ETL
## Overview of the Module 8 Challenge

An automated pipeline was created to take in new data, perform some transformations, and load the data into existing tables (Postgres) for movie titles. The data is taken from Wikipedia, Kaggle, and Movilens. 

### Folders/Files

Deliverable 1 - ETL_function_test.ipynb

Deliverable 2 - ETL_clean_wiki_movies_ipynb

Deliverable 3 - ETL_clean_kaggle_data.ipynb

Deliverable 4 - ETL_create_database.ipynb, 

Resource folder: wikipedia_movies.json, movies_metadata.csv, movies_query.png, ratings_query.png



## Results

The pipeline was created in order to be useful for extracting new data, transforming it, and loading it into SQL tables.

### Movies Query



!['movies_query'](https://github.com/DylanMontemayor/Movies-ETL/blob/main/Resources/movies_query.png)

### Ratings Query



![]()

## Summary

In this project, we were able to create an automated pipeline for processing movie data. The most extensive code in the jupyter notebooks is for transforming the data. It is important to manage adequately the ETL process to get the most and best data possible. 
